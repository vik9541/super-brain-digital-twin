# üß† PHASE 6: ADVANCED ML ‚Äî PLAN

**Status:** üìã Ready to Build  
**Estimated Time:** 2-3 weeks  
**Priority:** HIGH (Revenue/UX multiplier)  
**Tech Stack:** Python + OpenAI + scikit-learn + PostgreSQL  

---

## üéØ PHASE 6 GOAL

–ü—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å Contacts –∏–∑ "—Ç—É–ø–æ–≥–æ CRM" –≤ **"—É–º–Ω–æ–≥–æ —Å–æ–≤–µ—Ç–Ω–∏–∫–∞"**, –∫–æ—Ç–æ—Ä—ã–π:

1. **Recommends** ‚Äî "–¢—ã –¥–æ–ª–∂–µ–Ω –ø–æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è —Å –ò–≤–∞–Ω–æ–º" (semantic match)
2. **Predicts** ‚Äî "–ü–µ—Ç—Ä —Å–∫–æ—Ä–æ –ø–µ—Ä–µ—Å—Ç–∞–Ω–µ—Ç –±—ã—Ç—å –≤–∞–∂–Ω—ã–º –≤ —Ç–≤–æ–µ–π —Å–µ—Ç–∏" (churn prediction)
3. **Understands** ‚Äî "–¢–≤–æ–∏ –∫–æ–Ω—Ç–∞–∫—Ç—ã –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–æ–∑–∏—Ç–∏–≤–Ω—ã" (sentiment)
4. **Groups** ‚Äî "–í–æ—Ç 5 –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ –ø–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞–º" (clustering)

---

## üì¶ PHASE 6 COMPONENTS

### Component 1: Contact Embeddings (Semantic Search)

**–ß—Ç–æ:** –ö–∞–∂–¥—ã–π –∫–æ–Ω—Ç–∞–∫—Ç ‚Üí 1536-–º–µ—Ä–Ω—ã–π –≤–µ–∫—Ç–æ—Ä (OpenAI text-embedding-3-small)

**–ó–∞—á–µ–º:** 
- –ù–∞–π—Ç–∏ –ø–æ—Ö–æ–∂–∏—Ö –ª—é–¥–µ–π –ø–æ description/tags/organization
- "–ù–∞–π–¥–∏ –ª—é–¥–µ–π –ø–æ—Ö–æ–∂–∏—Ö –Ω–∞ –ü–µ—Ç—Ä–∞"
- Cluster –∫–æ–Ω—Ç–∞–∫—Ç—ã –ø–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞–º

**–§–∞–π–ª:** `api/ml/embeddings_service.py`

```python
class ContactEmbeddingsService:
    def __init__(self, supabase, openai_client):
        self.supabase = supabase
        self.client = openai_client
    
    async def generate_embedding(self, contact: Dict) -> np.ndarray:
        """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å embedding –¥–ª—è –∫–æ–Ω—Ç–∞–∫—Ç–∞"""
        # –ö–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è: first_name + last_name + organization + tags + notes
        text = f"{contact['first_name']} {contact['last_name']} \
                {contact.get('organization', '')} \
                {' '.join(contact.get('tags', []))}"
        
        response = await asyncio.to_thread(
            self.client.embeddings.create,
            input=text,
            model="text-embedding-3-small"
        )
        return np.array(response.data[0].embedding)
    
    async def find_similar_contacts(self, contact_id: str, top_n: int = 10) -> List[Dict]:
        """–ù–∞–π—Ç–∏ —Ç–æ–ø-N –ø–æ—Ö–æ–∂–∏—Ö –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤"""
        # 1. –ü–æ–ª—É—á–∏—Ç—å embedding target contact
        target_emb = await self.supabase.table('contact_embeddings')\
            .select('embedding').eq('contact_id', contact_id).execute()
        
        # 2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å pgvector –¥–ª—è similarity search
        # SELECT contact_id, 1 - (embedding <=> target_emb) as similarity
        # FROM contact_embeddings
        # ORDER BY similarity DESC LIMIT top_n
        
        similar = await self.supabase.rpc(
            'search_similar_contacts',
            {'target_embedding': target_emb[0]['embedding'], 'limit': top_n}
        ).execute()
        
        return similar.data
    
    async def batch_generate_embeddings(self, contacts: List[Dict]) -> None:
        """Batch –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å embeddings –¥–ª—è –≤—Å–µ—Ö –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ (nightly job)"""
        embeddings_data = []
        
        for contact in contacts:
            emb = await self.generate_embedding(contact)
            embeddings_data.append({
                'contact_id': contact['id'],
                'embedding': emb.tolist(),  # pgvector format
                'updated_at': datetime.utcnow().isoformat()
            })
        
        await self.supabase.table('contact_embeddings').upsert(embeddings_data).execute()
```

**GraphQL Query:**
```graphql
query {
  similarContacts(contactId: "uuid", limit: 10) {
    id
    firstName
    lastName
    similarity  # 0.0-1.0
    organization
  }
}
```

---

### Component 2: Contact Recommendations ("People You Should Know")

**–ß—Ç–æ:** ML –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç "–∫–∞–∫–∏–µ –∫–æ–Ω—Ç–∞–∫—Ç—ã —Ç—ã –¥–æ–ª–∂–µ–Ω –∑–Ω–∞—Ç—å" –Ω–∞ –æ—Å–Ω–æ–≤–µ:
- –¢–≤–æ–µ–π —Å–µ—Ç–∏ (–∫—Ç–æ —Ç—ã —É–∂–µ –∑–Ω–∞–µ—à—å)
- –ï–≥–æ —Å–µ—Ç–∏ (–∫—Ç–æ –æ–Ω –∑–Ω–∞–µ—Ç)
- –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ match (–ø–æ—Ö–æ–∂–∏–π —Ñ–æ–∫—É—Å/–∏–Ω—Ç–µ—Ä–µ—Å—ã)
- –ï–≥–æ influence (–≤–∞–∂–Ω—ã–π = —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º)

**–§–∞–π–ª:** `api/ml/recommendation_engine.py`

```python
class RecommendationEngine:
    def __init__(self, supabase, embeddings_service):
        self.supabase = supabase
        self.embeddings = embeddings_service
    
    async def recommend_contacts(
        self,
        user_contact_id: str,
        limit: int = 20,
        min_score: float = 0.6
    ) -> List[Dict]:
        """–†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–∞–∫—Ç—ã –¥–ª—è –∑–Ω–∞–∫–æ–º—Å—Ç–≤–∞"""
        
        recommendations = []
        
        # 1. –ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–∞–∫—Ç—ã –¥—Ä—É–∑–µ–π (2-hop network)
        friends_of_friends = await self._get_friends_of_friends(user_contact_id)
        
        # 2. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Å—á–∏—Ç–∞—Ç—å score:
        for candidate in friends_of_friends:
            score = await self._compute_recommendation_score(
                user_contact_id,
                candidate,
                weights={
                    'mutual_friends': 0.3,
                    'semantic_similarity': 0.3,
                    'influence_score': 0.25,
                    'same_organization': 0.15
                }
            )
            
            if score >= min_score:
                recommendations.append({
                    'contact_id': candidate['id'],
                    'score': score,
                    'reason': self._explain_reason(score, candidate),
                    **candidate
                })
        
        # 3. Sort by score, return top-N
        recommendations.sort(key=lambda x: x['score'], reverse=True)
        return recommendations[:limit]
    
    async def _compute_recommendation_score(
        self,
        user_id: str,
        candidate: Dict,
        weights: Dict
    ) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å score —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        score = 0.0
        
        # Mutual friends (–∫–æ–ª-–≤–æ –æ–±—â–∏—Ö –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤)
        mutual = await self._count_mutual_friends(user_id, candidate['id'])
        score += (mutual / 10.0) * weights['mutual_friends']  # Normalize
        
        # Semantic similarity (embedding match)
        similarity = await self.embeddings.get_similarity(
            user_id, candidate['id']
        )
        score += similarity * weights['semantic_similarity']
        
        # Influence score (–≤–∞–∂–Ω–æ—Å—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞)
        influence = candidate.get('influence_score', 0)
        score += influence * weights['influence_score']
        
        # Same organization bonus
        if candidate.get('organization') == user_contact['organization']:
            score += weights['same_organization']
        
        return min(score, 1.0)  # Cap at 1.0
    
    def _explain_reason(self, score: float, candidate: Dict) -> str:
        """–û–±—ä—è—Å–Ω–∏—Ç—å –ø–æ—á–µ–º—É —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º"""
        if score > 0.85:
            return f"Strong match: mutual friends + high influence"
        elif score > 0.7:
            return f"Good match: shares your interests"
        else:
            return f"Potential connection: {score*100:.0f}% match"
```

**GraphQL Query:**
```graphql
query {
  recommendedContacts(limit: 20, minScore: 0.6) {
    id
    firstName
    score
    reason
    influence
    organization
  }
}
```

---

### Component 3: Churn Prediction ("Who Will Become Unimportant?")

**–ß—Ç–æ:** –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –∫—Ç–æ –±—É–¥–µ—Ç —Ç–µ—Ä—è—Ç—å –∑–Ω–∞—á–∏–º–æ—Å—Ç—å –≤ —Ç–≤–æ–µ–π —Å–µ—Ç–∏

**–°–∏–≥–Ω–∞–ª—ã:**
- ‚Üì Frequency of interactions (emails/meetings/calls)
- ‚Üì Shared tags/groups
- ‚Üí Different organization (job change)
- ‚Üí Long time no contact (>3 months)

**–§–∞–π–ª:** `api/ml/churn_predictor.py`

```python
from sklearn.ensemble import RandomForestClassifier
import pickle

class ChurnPredictor:
    def __init__(self, supabase):
        self.supabase = supabase
        self.model = None  # Will load/train nightly
    
    async def predict_churn(
        self,
        contact_id: str
    ) -> Dict:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å "–≤—ã–ø–∞–¥–µ–Ω–∏—è" –∫–æ–Ω—Ç–∞–∫—Ç–∞"""
        
        # 1. –ò–∑–≤–ª–µ—á—å features
        features = await self._extract_features(contact_id)
        
        # 2. Predict
        churn_probability = self.model.predict_proba([features])[0][1]
        
        return {
            'contact_id': contact_id,
            'churn_probability': churn_probability,  # 0.0-1.0
            'risk_level': self._risk_level(churn_probability),
            'interventions': self._suggest_interventions(features)
        }
    
    async def _extract_features(self, contact_id: str) -> List[float]:
        """–ò–∑–≤–ª–µ—á—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏"""
        contact = await self.supabase.table('apple_contacts').select('*')\
            .eq('id', contact_id).execute()
        
        # Get interaction history
        sync_history = await self.supabase.table('contact_sync_history')\
            .select('*').eq('contact_id', contact_id)\
            .order('created_at', desc=True).limit(12).execute()
        
        features = [
            # 1. Days since last update
            (datetime.utcnow() - contact['updated_at']).days / 365,
            
            # 2. Interaction frequency (interactions per month, last 3 months)
            len([s for s in sync_history if (datetime.utcnow() - s['created_at']).days < 90]) / 3,
            
            # 3. Influence score (higher influence = lower churn)
            1.0 - (contact['influence_score'] or 0),
            
            # 4. Number of tags (more tags = more connected)
            len(contact.get('tags', [])) / 10,
            
            # 5. Community size (bigger community = lower churn)
            await self._get_community_size(contact['community_id']) / 100,
        ]
        
        return features
    
    def _risk_level(self, probability: float) -> str:
        """–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞"""
        if probability > 0.7:
            return "HIGH"
        elif probability > 0.4:
            return "MEDIUM"
        else:
            return "LOW"
    
    def _suggest_interventions(self, features: List[float]) -> List[str]:
        """–ß—Ç–æ –¥–µ–ª–∞—Ç—å, —á—Ç–æ–±—ã –Ω–µ –ø–æ—Ç–µ—Ä—è—Ç—å –∫–æ–Ω—Ç–∞–∫—Ç"""
        suggestions = []
        
        if features[0] > 0.5:  # Days since update
            suggestions.append("Reach out - no recent contact")
        
        if features[1] < 0.1:  # Low interaction
            suggestions.append("Schedule a meeting")
        
        if features[4] < 0.2:  # Small community
            suggestions.append("Introduce to others in your network")
        
        return suggestions
    
    async def train_model(self, training_data: List[Tuple]) -> None:
        """–¢—Ä–µ–Ω–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å (nightly job, —Ä–∞–∑ –≤ –Ω–µ–¥–µ–ª—é)"""
        X = [t[0] for t in training_data]  # Features
        y = [t[1] for t in training_data]  # Labels (churned=1, active=0)
        
        self.model = RandomForestClassifier(n_estimators=100, max_depth=10)
        self.model.fit(X, y)
        
        # Save model to disk or DB
        model_bytes = pickle.dumps(self.model)
        await self.supabase.table('ml_models').upsert({
            'model_name': 'churn_predictor',
            'model_data': model_bytes,
            'trained_at': datetime.utcnow().isoformat()
        }).execute()
```

**GraphQL Query:**
```graphql
query {
  churnRisk(contactId: "uuid") {
    probability  # 0.0-1.0
    riskLevel    # HIGH, MEDIUM, LOW
    interventions  # ["Reach out", ...]
  }
}
```

---

### Component 4: Sentiment Analysis (Contact Tone/Vibe)

**–ß—Ç–æ:** –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å "—Ç–æ–Ω" –∫–æ–Ω—Ç–∞–∫—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ:
- Tags (positive: "mentor", "friend"; negative: "difficult", "skeptical")
- Notes (–µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å)
- Interaction history (—á–∞—Å—Ç–æ—Ç–∞, –ø–æ–∑–∏—Ç–∏–≤/–Ω–µ–≥–∞—Ç–∏–≤)

**–§–∞–π–ª:** `api/ml/sentiment_analyzer.py`

```python
from textblob import TextBlob

class SentimentAnalyzer:
    def __init__(self, supabase):
        self.supabase = supabase
    
    async def analyze_contact_sentiment(self, contact_id: str) -> Dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å '—Ç–æ–Ω' –∫–æ–Ω—Ç–∞–∫—Ç–∞"""
        
        contact = await self.supabase.table('apple_contacts').select('*')\
            .eq('id', contact_id).execute()
        
        # 1. Tag-based sentiment
        tag_sentiment = self._analyze_tags(contact.get('tags', []))
        
        # 2. Notes-based sentiment (–µ—Å–ª–∏ –µ—Å—Ç—å)
        notes_sentiment = 0.0
        if contact.get('notes'):
            blob = TextBlob(contact['notes'])
            notes_sentiment = blob.sentiment.polarity  # -1 to 1
        
        # 3. Interaction pattern (—á–∞—Å—Ç—ã–µ –∫–æ–Ω—Ç–∞–∫—Ç—ã = –ø–æ–∑–∏—Ç–∏–≤)
        interaction_sentiment = await self._analyze_interaction_pattern(contact_id)
        
        # Weighted average
        overall_sentiment = (
            tag_sentiment * 0.4 +
            notes_sentiment * 0.3 +
            interaction_sentiment * 0.3
        )
        
        return {
            'contact_id': contact_id,
            'overall_sentiment': overall_sentiment,  # -1 to 1
            'sentiment_label': self._sentiment_label(overall_sentiment),
            'components': {
                'tags': tag_sentiment,
                'notes': notes_sentiment,
                'interactions': interaction_sentiment
            }
        }
    
    def _analyze_tags(self, tags: List[str]) -> float:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å tags"""
        positive_tags = {'mentor', 'friend', 'collaborator', 'advisor', 'supporter'}
        negative_tags = {'difficult', 'skeptical', 'competitor', 'rival'}
        
        positive_count = len([t for t in tags if t.lower() in positive_tags])
        negative_count = len([t for t in tags if t.lower() in negative_tags])
        total = positive_count + negative_count
        
        if total == 0:
            return 0.0  # Neutral
        
        return (positive_count - negative_count) / total
    
    def _sentiment_label(self, sentiment: float) -> str:
        """–¢–µ–∫—Å—Ç–æ–≤—ã–π –ª–µ–π–±–ª"""
        if sentiment > 0.5:
            return "Very Positive"
        elif sentiment > 0.2:
            return "Positive"
        elif sentiment > -0.2:
            return "Neutral"
        elif sentiment > -0.5:
            return "Negative"
        else:
            return "Very Negative"
```

**GraphQL Query:**
```graphql
query {
  contactSentiment(contactId: "uuid") {
    overallSentiment  # -1 to 1
    label             # "Very Positive", etc
  }
}
```

---

### Component 5: Contact Clustering (Interest Groups)

**–ß—Ç–æ:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–∞–∫—Ç—ã –ø–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞–º (K-means)

**–ó–∞—á–µ–º:** –í–∏–¥–µ—Ç—å "–∫—Ç–æ —Å –∫–µ–º –æ–±—â–∞–µ—Ç—Å—è" –ø–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞–º

**–§–∞–π–ª:** `api/ml/clustering_service.py`

```python
from sklearn.cluster import KMeans
import numpy as np

class ContactClusteringService:
    def __init__(self, supabase, embeddings_service):
        self.supabase = supabase
        self.embeddings = embeddings_service
    
    async def cluster_contacts(self, n_clusters: int = 5) -> Dict:
        """–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–∞–∫—Ç—ã –ø–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞–º"""
        
        # 1. –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ embeddings
        embeddings_data = await self.supabase.table('contact_embeddings')\
            .select('contact_id, embedding').execute()
        
        embeddings = np.array([e['embedding'] for e in embeddings_data])
        contact_ids = [e['contact_id'] for e in embeddings_data]
        
        # 2. K-means clustering
        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        labels = kmeans.fit_predict(embeddings)
        
        # 3. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å clusters
        clusters = defaultdict(list)
        for contact_id, label in zip(contact_ids, labels):
            clusters[int(label)].append(contact_id)
        
        # 4. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ DB
        for cluster_id, contacts in clusters.items():
            await self.supabase.table('contact_clusters').upsert({
                'cluster_id': cluster_id,
                'contacts': contacts,
                'cluster_size': len(contacts),
                'created_at': datetime.utcnow().isoformat()
            }).execute()
        
        return {
            'total_clusters': n_clusters,
            'clusters': dict(clusters),
            'cluster_sizes': {k: len(v) for k, v in clusters.items()}
        }
```

**GraphQL Query:**
```graphql
query {
  contactClusters {
    id
    size
    topTopics  # Inferred from contact tags in cluster
  }
}
```

---

## üìä PHASE 6 DATABASE SCHEMA ADDITIONS

```sql
-- Contact embeddings (pgvector)
CREATE TABLE contact_embeddings (
    contact_id UUID PRIMARY KEY,
    embedding vector(1536),  -- OpenAI text-embedding-3-small
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_contact_embeddings_cosine ON contact_embeddings
    USING ivfflat (embedding vector_cosine_ops);

-- Contact recommendations
CREATE TABLE contact_recommendations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_contact_id UUID NOT NULL,
    recommended_contact_id UUID NOT NULL,
    score NUMERIC(5,4),
    reason TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Churn predictions
CREATE TABLE churn_predictions (
    contact_id UUID PRIMARY KEY,
    churn_probability NUMERIC(5,4),
    risk_level TEXT,  -- HIGH, MEDIUM, LOW
    interventions TEXT[],
    predicted_at TIMESTAMPTZ DEFAULT NOW()
);

-- Contact sentiment
CREATE TABLE contact_sentiment (
    contact_id UUID PRIMARY KEY,
    overall_sentiment NUMERIC(5,3),  -- -1 to 1
    sentiment_label TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Contact clusters
CREATE TABLE contact_clusters (
    cluster_id INT,
    contact_id UUID,
    cluster_size INT,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- ML models (versioning)
CREATE TABLE ml_models (
    model_name TEXT,
    model_data BYTEA,  -- Pickled scikit-learn model
    trained_at TIMESTAMPTZ,
    accuracy NUMERIC(5,4),  -- For churn predictor
    PRIMARY KEY (model_name, trained_at)
);
```

---

## üîÑ PHASE 6 NIGHTLY PIPELINE

–î–æ–±–∞–≤–∏—Ç—å –≤ `scheduler.py`:

```python
@scheduler.scheduled_job("cron", hour=4, minute=0)
async def phase6_embeddings_job():
    """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å embeddings –¥–ª—è –≤—Å–µ—Ö –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ (nightly)"""
    contacts = supabase.table('apple_contacts').select('*').execute().data
    service = ContactEmbeddingsService(supabase, openai_client)
    await service.batch_generate_embeddings(contacts)
    logger.info("‚úÖ Embeddings generated for all contacts")

@scheduler.scheduled_job("cron", hour=4, minute=15)
async def phase6_recommendations_job():
    """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å recommendations"""
    engine = RecommendationEngine(supabase, embeddings_service)
    contacts = supabase.table('apple_contacts').select('id').execute().data
    
    for contact in contacts:
        recommendations = await engine.recommend_contacts(
            contact['id'],
            limit=20,
            min_score=0.6
        )
        # Save to DB
    
    logger.info("‚úÖ Recommendations generated")

@scheduler.scheduled_job("cron", hour=4, minute=30)
async def phase6_churn_job():
    """–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å churn (—Ä–∞–∑ –≤ –Ω–µ–¥–µ–ª—é)"""
    predictor = ChurnPredictor(supabase)
    
    # Train model
    training_data = await prepare_training_data(supabase)
    await predictor.train_model(training_data)
    
    # Predict for all contacts
    contacts = supabase.table('apple_contacts').select('id').execute().data
    for contact in contacts:
        prediction = await predictor.predict_churn(contact['id'])
        # Save to DB
    
    logger.info("‚úÖ Churn predictions updated")

@scheduler.scheduled_job("cron", hour=4, minute=45)
async def phase6_sentiment_job():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å sentiment"""
    analyzer = SentimentAnalyzer(supabase)
    contacts = supabase.table('apple_contacts').select('*').execute().data
    
    for contact in contacts:
        sentiment = await analyzer.analyze_contact_sentiment(contact['id'])
        # Save to DB
    
    logger.info("‚úÖ Sentiment analysis completed")

@scheduler.scheduled_job("cron", hour=5, minute=0)
async def phase6_clustering_job():
    """–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–∞–∫—Ç—ã"""
    clustering = ContactClusteringService(supabase, embeddings_service)
    result = await clustering.cluster_contacts(n_clusters=5)
    logger.info(f"‚úÖ Clustering complete: {result['total_clusters']} clusters")
```

---

## üöÄ PHASE 6 GraphQL ADDITIONS

```graphql
type Query {
    # Embeddings
    similarContacts(contactId: UUID!, limit: Int): [Contact!]!
    
    # Recommendations
    recommendedContacts(limit: Int, minScore: Float): [ContactRecommendation!]!
    
    # Churn Prediction
    churnRisk(contactId: UUID!): ChurnPrediction!
    allChurnRisks(riskLevel: String): [ChurnPrediction!]!
    
    # Sentiment
    contactSentiment(contactId: UUID!): ContactSentiment!
    sentimentOverview: SentimentStats!
    
    # Clustering
    contactClusters: [ContactCluster!]!
    clusterDetails(clusterId: Int!): ClusterDetails!
}

type ContactRecommendation {
    id: UUID!
    score: Float!
    reason: String!
    contact: Contact!
}

type ChurnPrediction {
    contactId: UUID!
    probability: Float!  # 0.0-1.0
    riskLevel: String!   # HIGH, MEDIUM, LOW
    interventions: [String!]!
}

type ContactSentiment {
    contactId: UUID!
    overallSentiment: Float!  # -1 to 1
    label: String!  # "Very Positive", etc
}

type SentimentStats {
    averageSentiment: Float!
    positiveCount: Int!
    neutralCount: Int!
    negativeCount: Int!
}

type ContactCluster {
    id: Int!
    size: Int!
    topTopics: [String!]!
    members: [Contact!]!
}
```

---

## üìä PHASE 6 WEB UI ADDITIONS

–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ `web/app/dashboard/`:

1. **`recommendations/page.tsx`**
   - "People You Should Know"
   - Cards —Å score + reason
   - "Connect" button

2. **`churn-analysis/page.tsx`**
   - –¢–∞–±–ª–∏—Ü–∞ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ —Å churn_probability
   - Filter by risk level
   - Interventions suggestions

3. **`sentiment-analysis/page.tsx`**
   - Overall sentiment distribution (pie chart)
   - Per-contact sentiment labels
   - Sentiment trends over time

4. **`interest-clusters/page.tsx`**
   - Clusters visualization (circles/bubbles)
   - Click cluster ‚Üí see members
   - Inferred topics per cluster

---

## ‚úÖ PHASE 6 "DONE" CRITERIA

- [ ] Contact embeddings (text-embedding-3-small via OpenAI)
- [ ] pgvector installed in Supabase
- [ ] Similarity search working (find_similar_contacts)
- [ ] Recommendation engine implemented
- [ ] Churn predictor trained (RandomForest)
- [ ] Sentiment analyzer working
- [ ] Contact clustering (K-means)
- [ ] All 5 nightly jobs running
- [ ] All GraphQL queries implemented
- [ ] 5 new web pages created
- [ ] Tests written (unit + integration)
- [ ] Documentation updated

**–ò—Ç–æ–≥–æ:** ~3,000+ —Å—Ç—Ä–æ–∫ Python + ~1,500 —Å—Ç—Ä–æ–∫ React

---

## üìà REVENUE/UX IMPACT

**After Phase 6 complete:**

‚ú® **"Smart CRM"** ‚Äî —Å–∏—Å—Ç–µ–º–∞, –∫–æ—Ç–æ—Ä–∞—è:
- –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç –∫–æ–≥–æ –Ω—É–∂–Ω–æ –ø–æ–∑–Ω–∞–∫–æ–º–∏—Ç—å ‚Üí –±–æ–ª—å—à–µ –ø—Ä–æ–¥–∞–∂
- –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–µ—Ç –æ –ø–æ—Ç–µ—Ä–µ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ ‚Üí –ª—É—á—à–µ manage relationships
- –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –ø–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞–º ‚Üí –ª—É—á—à–µ –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞—Ç—å —Å–µ—Ç—å
- –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–æ–Ω ‚Üí –ª—É—á—à–µ –ø–æ–Ω–∏–º–∞—Ç—å –æ—Ç–Ω–æ—à–µ–Ω–∏—è

üí∞ **Monetization potential:**
- B2B: Sales teams (finding leads)
- B2C: Networking apps
- Enterprise: HR/recruiting

---

## üéØ NEXT STEPS

1. **Setup OpenAI API key** (for embeddings)
2. **Add pgvector to Supabase** (in DB)
3. **Implement Component 1** (Embeddings) ‚Üí test
4. **Implement Component 2** (Recommendations) ‚Üí test
5. **Implement Component 3** (Churn) ‚Üí train model
6. **Implement Component 4** (Sentiment) ‚Üí test
7. **Implement Component 5** (Clustering) ‚Üí visualize
8. **Add to nightly pipeline**
9. **Add GraphQL queries**
10. **Build web UI pages**
11. **Test end-to-end**
12. **Deploy**

---

**Phase 6 = "AI-Powered CRM"**

–ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ Contacts v2.0 –±—É–¥–µ—Ç –≥–æ—Ç–æ–≤–∞ –∫:
- Enterprise sales
- Venture capital
- IPO readiness

**Let's build the future of contact management.** üöÄ
