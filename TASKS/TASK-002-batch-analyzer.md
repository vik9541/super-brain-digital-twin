# üìÉ TASK-002: Batch Analyzer CronJob

**–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–µ –¢–ò–ú:–ú AI-ML –æ—Ç–¥–µ–ª**

| –†–æ–ª—å | –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å | –¢—Ä–µ–±—É–µ–º—ã–µ –ö–Ω–∞–Ω–∏—è |
|:---:|:---|:---:|
| **Dmitry K.** (ML Ops Lead) | Kubernetes CronJob YAML | kubectl, helm, K8s |
| **Natalia V.** (Data Science) | batch_analyzer.py –ª–æ–≥–∏–∫–∞ | Python, Pandas, SQL |
| **Andrey M.** (AI Lead) | Perplexity API –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è | API, async/await |
| **Igor S.** (NLP Specialist) | –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ | NLP, parsing |

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü° IMPORTANT  
**–ù–∞ –¥–∞—Ç—É:** –°—Ä–µ–¥–∞, 9 –¥–µ–∫–∞–±—Ä—è 2025  
**–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:** 6 —á–∞—Å–æ–≤  
**–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:** TASK-001 (Bot) –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å 

---

## üèóÔ∏è –ê–†–•–ò–¢–ï–ö–¢–£–†–ê

```
Supabase Database
    ‚Üë (SELECT projects WHERE status='active')
    ‚îÇ
    ‚îî‚îÄ batch_analyzer.py (CronJob Pod)
    ‚îÇ   ‚îî‚îÄ –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è –≤ 02:00 UTC
    ‚îÇ   ‚îî‚îÄ –ü—Ä–æ–≤–µ—Ä–∏—Ç –∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã
    ‚îÇ   ‚îî‚îÄ –û—Ç—Ä–∞–≤–∏—Ç –∫–∞–∂–¥—ã–π –≤ Perplexity API
    ‚îÇ   ‚îî‚îÄ –û—Ç–ø—Ä–∞–≤–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ Telegram
    ‚îÇ
    ‚îî‚îÄ K8s API (Prometheus metrics)
         ‚îî‚îÄ batch.duration_seconds
         ‚îî‚îÄ batch.projects_processed
         ‚îî‚îÄ batch.errors_count
```

---

## üìä –ü–û–ù–ï–¥–ï–õ–¨–ù–û-–ü–¶–ò–ö–õ–û–ì–†–ê–ú–ú–ê

### –≠—Ç–∞–ø 1: K8s CronJob YAML (09:00-10:30)

**–§–∞–π–ª:** `k8s/batch-analyzer-cronjob.yaml`

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: batch-analyzer
  namespace: production
spec:
  # –ß–∞—Å 2:00 AM UTC –∫–∞–∂–¥—ã–µ —Å—É—Ç–∫–∏
  schedule: "0 2 * * *"
  
  # –ù–µ u0434–µ—Ä–∂–∏–≤–∞—Ç—å –±–æ–ª–µ–µ 3 –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—É—Å–∫–æ–≤
  concurrencyPolicy: Forbid
  
  # –í—ã–ø–æ–ª–Ω—è—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–µ Job –µ—Å–ª–∏ –æ–Ω–∏ –µ—â–µ —Ä–∞–±–æ—Ç–∞—é—Ç
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  
  jobTemplate:
    spec:
      backoffLimit: 2  # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
      activeDeadlineSeconds: 3600  # 1 —á–∞—Å –º–∞–∫—Å
      
      template:
        spec:
          serviceAccountName: batch-analyzer
          restartPolicy: OnFailure
          
          containers:
          - name: analyzer
            image: registry.digitalocean.com/digital-twin-registry/batch-analyzer:latest
            imagePullPolicy: Always
            
            # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
            env:
            - name: SUPABASE_URL
              valueFrom:
                secretKeyRef:
                  name: supabase-secrets
                  key: url
            - name: SUPABASE_KEY
              valueFrom:
                secretKeyRef:
                  name: supabase-secrets
                  key: key
            - name: PERPLEXITY_API_KEY
              valueFrom:
                secretKeyRef:
                  name: perplexity-secrets
                  key: api-key
            - name: TELEGRAM_BOT_TOKEN
              valueFrom:
                secretKeyRef:
                  name: telegram-secrets
                  key: bot-token
            
            # –†–µ—Å—É—Ä—Å—ã
            resources:
              requests:
                cpu: 500m
                memory: 1Gi
              limits:
                cpu: 2000m
                memory: 2Gi
            
            # Liveness & Readiness
            livenessProbe:
              exec:
                command:
                - /bin/sh
                - -c
                - test -f /tmp/batch_running || exit 0
              initialDelaySeconds: 30
              periodSeconds: 60
```

**–ö–æ–º–∞–Ω–¥—ã:**
```bash
# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å YAML
git add k8s/batch-analyzer-cronjob.yaml

# –ù–∞–Ω–µ—Å—Ç–∏ –≤ K8s
kubectl apply -f k8s/batch-analyzer-cronjob.yaml

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å
kubectl get cronjobs -n production
```

---

### –≠—Ç–∞–ø 2: Python batch_analyzer.py (10:30-13:00)

**–§–∞–π–ª:** `bot/batch_analyzer.py`

```python
import asyncio
import os
from datetime import datetime
from typing import List, Dict
import aiohttp
from supabase import create_client
from telegram import Bot
import logging

# –ö–æ–Ω—Ñ–∏–≥
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
PERPLEXITY_API_KEY = os.getenv("PERPLEXITY_API_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
DEFAULT_USER_ID = int(os.getenv("DEFAULT_USER_ID"))

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

class BatchAnalyzer:
    def __init__(self):
        self.supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        self.bot = Bot(token=TELEGRAM_BOT_TOKEN)
        self.perplexity_url = "https://api.perplexity.ai/openai/v1/chat/completions"
        self.stats = {
            "processed": 0,
            "errors": 0,
            "start_time": datetime.now()
        }
    
    async def get_active_projects(self) -> List[Dict]:
        """–ü–æ–ª—É—á–∏ –∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã –∏–∑ Supabase"""
        try:
            response = self.supabase.table("projects").select("*").eq("status", "active").execute()
            return response.data
        except Exception as e:
            logger.error(f"Error fetching projects: {e}")
            return []
    
    async def analyze_project_with_ai(self, project: Dict) -> str:
        """–ü–æ—à–ª–∏ –ø—Ä–æ–µ–∫—Ç –≤ Perplexity –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        prompt = f"""
        Analyze this project:
        - Name: {project['name']}
        - Description: {project['description']}
        - Status: {project['status']}
        - Progress: {project['progress']}%
        
        Provide:
        1. Quick assessment
        2. Risks identified
        3. Next steps
        """
        
        try:
            async with aiohttp.ClientSession() as session:
                headers = {
                    "Authorization": f"Bearer {PERPLEXITY_API_KEY}",
                    "Content-Type": "application/json"
                }
                payload = {
                    "model": "sonar-reasoning-pro",
                    "messages": [{"role": "user", "content": prompt}],
                    "max_tokens": 500
                }
                
                async with session.post(self.perplexity_url, json=payload, headers=headers) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        return data["choices"][0]["message"]["content"]
                    else:
                        logger.error(f"Perplexity API error: {resp.status}")
                        return "Analysis failed"
        except Exception as e:
            logger.error(f"Error analyzing project: {e}")
            self.stats["errors"] += 1
            return f"Error: {str(e)}"
    
    async def send_telegram_report(self, project: Dict, analysis: str):
        """–ü–æ—à–ª–∏ –æ—Ç—á–µ—Ç –≤ Telegram"""
        try:
            message = f"""
            üìä **Batch Analysis Report**
            
            **Project:** {project['name']}
            **Progress:** {project['progress']}%
            
            **AI Analysis:**
            {analysis}
            
            ‚è∞ Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}
            """
            
            await self.bot.send_message(
                chat_id=DEFAULT_USER_ID,
                text=message,
                parse_mode="Markdown"
            )
            self.stats["processed"] += 1
        except Exception as e:
            logger.error(f"Error sending telegram: {e}")
            self.stats["errors"] += 1
    
    async def run(self):
        """–ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª batch analyzer"""
        logger.info("Starting batch analyzer...")
        
        projects = await self.get_active_projects()
        logger.info(f"Found {len(projects)} active projects")
        
        for project in projects:
            logger.info(f"Analyzing project: {project['name']}")
            analysis = await self.analyze_project_with_ai(project)
            await self.send_telegram_report(project, analysis)
        
        # –û—Ç–ø—Ä–∞–≤—å –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
        duration = (datetime.now() - self.stats["start_time"]).total_seconds()
        summary = f"""
        ‚úÖ **Batch Analysis Complete**
        
        **Stats:**
        - Projects processed: {self.stats['processed']}
        - Errors: {self.stats['errors']}
        - Duration: {duration:.1f} seconds
        
        ‚è∞ {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}
        """
        
        await self.bot.send_message(
            chat_id=DEFAULT_USER_ID,
            text=summary,
            parse_mode="Markdown"
        )

async def main():
    analyzer = BatchAnalyzer()
    await analyzer.run()

if __name__ == "__main__":
    asyncio.run(main())
```

---

### –≠—Ç–∞–ø 3: Docker Image (13:00-14:00)

**–§–∞–π–ª:** `Dockerfile.batch-analyzer`

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY bot/ .

CMD ["python", "batch_analyzer.py"]
```

**requirements.txt:**
```
aiohttp==3.9.1
supabase==2.4.0
python-telegram-bot==21.0
pydantic==2.5.0
python-dotenv==1.0.0
```

**–ö–æ–º–∞–Ω–¥—ã:**
```bash
# –°–æ–±—Ä–∞—Ç—å –∏–º–∞–∂
docker build -f Dockerfile.batch-analyzer -t registry.digitalocean.com/digital-twin-registry/batch-analyzer:latest .

# –ü—É—à–∏—Ç—å –≤ registry
docker push registry.digitalocean.com/digital-twin-registry/batch-analyzer:latest
```

---

### –≠—Ç–∞–ø 4: K8s Deployment + Testing (14:00-15:00)

**–ö–æ–º–∞–Ω–¥—ã:**
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å CronJob —Å–æ—Å—Ç–æ—è–Ω–∏–µ
kubectl get cronjobs -n production
kubectl describe cronjob batch-analyzer -n production

# –ú–∞–Ω—É–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
kubectl create job --from=cronjob/batch-analyzer test-batch -n production

# –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –∑–∞–ø—É—Å–∫
kubectl get jobs -n production -w
kubectl logs job/test-batch -n production -f

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –æ—à–∏–±–∫–∏
kubectl describe pod <pod-name> -n production
```

---

## ‚úÖ –ö—Ä–∏—Ç–µ—Ä–∏–∏ –£–°–ü–ï–•–ê

- [ ] CronJob —Å–æ–∑–¥–∞–Ω (kubectl get cronjobs)
- [ ] batch_analyzer.py —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ
- [ ] Docker –∏–º–∞–∂ –≤ registry
- [ ] Job –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –≤—Ä—É—á–Ω—É—é
- [ ] Telegram –æ—Ç—á–µ—Ç –ø–æ–ª—É—á–µ–Ω
- [ ] Prometheus –º–µ—Ç—Ä–∏–∫–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É—é—Ç—Å—è

---

## üîó –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- **Kubernetes CronJob:** https://github.com/kubernetes/kubernetes
- **Kubeflow:** https://github.com/kubeflow/kubeflow
- **Supabase Python:** https://github.com/supabase/supabase-py
- **Telegram Bot:** https://github.com/python-telegram-bot/python-telegram-bot
- **Perplexity API:** https://docs.perplexity.ai

---

**–°–æ—Å—Ç–æ—è–Ω–∏–µ:** üü¢ READY FOR EXECUTION  
**–í—Ä–µ–º—è —Å–Ω–æ–≤–∞ –∂–µ–Ω–∏–µ:** 7 –¥–µ–∫–∞–±—Ä—è 2025